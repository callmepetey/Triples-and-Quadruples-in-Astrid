{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Tuples with Separation 30 kpc < dr < 200 kpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Tuples Information.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from bigfile import BigFile\n",
    "import glob, os, struct\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "import astropy.units as u\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set ()\n",
    "sns.set_palette (\"Set2\")\n",
    "sns.set_style ('ticks', {'ytick.direction' : 'in', 'xtick.direction' : 'in'})\n",
    "\n",
    "cmap = plt.get_cmap (\"Set2\")\n",
    "sns.set_context (\"paper\", font_scale = 1.7, rc = {\"axes.linewidth\" : 1.3, \"lines.linewidth\" : 2.5, \"patch.linewidth\" : 2.2})\n",
    "from matplotlib import rcParams as rc\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import import_ipynb\n",
    "import Tuples_Information as tuples_z2_z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the cosmological parameters\n",
    "hh = 0.6774\n",
    "from colossus.cosmology import cosmology\n",
    "params = {'flat' : True, 'H0' : 67.74, 'Om0' : 0.2865, 'Ob0' : 0.04628, 'sigma8' : 0.82, 'ns' : 0.96}\n",
    "cosmo = cosmology.setCosmology ('myCosmo', params)\n",
    "\n",
    "# some constants and unit conversions\n",
    "msun_mks = 1.989e30\n",
    "pc_mks = 3.086e16\n",
    "grav_mks = 6.67e-11\n",
    "km_mks = 1e3\n",
    "yr_mks = 3.154e+7\n",
    "c_mks = 3e8\n",
    "\n",
    "Mpc_to_m = 3.086e+22\n",
    "m_to_mpc = 1.0 / Mpc_to_m\n",
    "s_to_year = 3.17098e-8\n",
    "c_Mpc_yr = c_mks * m_to_mpc / s_to_year\n",
    "\n",
    "\n",
    "# conversion between time and redshift\n",
    "z_arr = np.linspace (0, 10, 500)\n",
    "time = cosmo.age (z_arr) # Gyr\n",
    "def z_to_t (x):\n",
    "    return interp1d (z_arr, time, fill_value = 'extrapolate')(x)\n",
    "def t_to_z (x):\n",
    "    return interp1d(time, z_arr, fill_value = 'extrapolate')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_mks = 3e8\n",
    "msun_mks = 2e30\n",
    "s_to_year = 3.17098e-8\n",
    "year_to_s = 1./s_to_year\n",
    "lsun_ergs = 3.9e33\n",
    "mdot_msun_yr = 1e10/980/1e6\n",
    "def calc_lx(mdot):\n",
    "    \"\"\"\n",
    "    input: mdot in Msun/yr\n",
    "    output: Lx in ergs\n",
    "    \"\"\"\n",
    "    lbol = 0.1*mdot*msun_mks/year_to_s*c_mks**2\n",
    "    lbol_lsun = lbol/3.9e26\n",
    "    k = 10.83*(lbol_lsun/1e10)**0.28 \\\n",
    "        + 6.08*(lbol_lsun/1e10)**(-0.02)\n",
    "    return lbol/k*1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = 3.0\n"
     ]
    }
   ],
   "source": [
    "# BigFile opens up a snapshot to be read\n",
    "# snapshot 214 stores the z=3 information\n",
    "\n",
    "# pig = BigFile('/hildafs/datasets/Asterix/PIG2/PIG_348')\n",
    "pig = BigFile('/hildafs/datasets/Asterix/PIG_files/PIG_214')\n",
    "\n",
    "BH_IDs = pig.open('5/ID')[:]\n",
    "BH_pos = pig.open('5/Position')[:]\n",
    "BH_mass = pig.open('5/BlackholeMass')\n",
    "\n",
    "FOFGroups_MassByType = pig.open('FOFGroups/MassByType')[:]\n",
    "\n",
    "# you can check the redshift by reading the attributes of the snapshot\n",
    "battr = pig[\"Header\"].attrs\n",
    "scale_fac = battr[\"Time\"][0]\n",
    "redshift = 1.0 / battr[\"Time\"][0] - 1\n",
    "print('z =', redshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total pairs with separation 30kpc < dr < 200kpc: 794\n",
      "after mass cut: 794\n"
     ]
    }
   ],
   "source": [
    "# pairs_all are selected based on the z coordinate separation\n",
    "# we did not make any mass or luminosity cut here\n",
    "\n",
    "# pairs_all = np.load ('/hildafs/projects/phy200018p/share/calvin_2022/pair-m1e7-dr=200kpc-pig348.npy')\n",
    "pairs_all = np.load ('/hildafs/projects/phy200018p/share/calvin_2022/pair-m1e7-dr=200kpc-pig214.npy')\n",
    "\n",
    "\n",
    "# now we select pairs with the true separation 30kpc < dr < 200kpc\n",
    "maskdr = pairs_all['dr'] < 200\n",
    "maskdr &= pairs_all['dr'] > 30\n",
    "pairs = pairs_all[maskdr]\n",
    "print('total pairs with separation 30kpc < dr < 200kpc:', len (pairs))\n",
    "# lb1 = np.maximum(pairs['lb1'],pairs['lb2'])\n",
    "# lb2 = np.minimum(pairs['lb1'],pairs['lb2'])\n",
    "\n",
    "# mass only\n",
    "mask7 = pairs['m1'] * 1e10 / hh > 1e7\n",
    "mask7 &= pairs['m2']* 1e10 / hh > 1e7\n",
    "duals_massive = pairs[mask7]\n",
    "print ('after mass cut:', len (duals_massive))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(duals_massive)\n",
    "potential_triples = []\n",
    "\n",
    "for i in range(length):\n",
    "    dual = duals_massive[i]\n",
    "    id1, id2 = dual['id1'], dual['id2']\n",
    "    \n",
    "    for j in range(length):\n",
    "        if i != j:\n",
    "            itt = duals_massive[j]\n",
    "            id3, id4 = itt['id1'], itt['id2']\n",
    "            \n",
    "            temp = []\n",
    "            \n",
    "            if id1 == id3: temp = sorted([id1, id2, id4])\n",
    "            elif id1 == id4: temp = sorted([id1, id2, id3])\n",
    "            elif id2 == id3: temp = sorted([id1, id2, id4])\n",
    "            elif id2 == id4: temp = sorted([id1, id2, id3])\n",
    "            \n",
    "            if temp != []: potential_triples.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_duals(x, y):\n",
    "    id1, id2 = x[0], x[1]\n",
    "    id3, id4 = y[0], y[1]\n",
    "    \n",
    "    if sorted([id1, id2]) == sorted([id3, id4]): return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(potential_triples)\n",
    "triples = []\n",
    "dual_ids = duals_massive[['id1','id2']][:]\n",
    "\n",
    "for i in range(length):\n",
    "    pot = potential_triples[i]\n",
    "    id1, id2, id3 = pot[0], pot[1], pot[2]\n",
    "    \n",
    "    p1, p2, p3 = (id1, id2), (id1, id3), (id2, id3)\n",
    "    \n",
    "    b1, b2, b3 = False, False, False\n",
    "    \n",
    "    for dual in dual_ids:\n",
    "        if comp_duals(p1, dual): b1 = True\n",
    "        elif comp_duals(p2, dual): b2 = True\n",
    "        elif comp_duals(p3, dual): b3 = True\n",
    "            \n",
    "    if False not in [b1, b2, b3]:\n",
    "        if sorted(pot) not in triples:\n",
    "            triples.append(sorted(pot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total potential triples with separation 30kpc < dr < 200kpc: 1176\n",
      "total triples with separation 30kpc < dr < 200kpc (with potential quadruples): 126\n"
     ]
    }
   ],
   "source": [
    "print('total potential triples with separation 30kpc < dr < 200kpc:', len(potential_triples))\n",
    "print('total triples with separation 30kpc < dr < 200kpc (with potential quadruples):', len(triples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadruples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(triples)\n",
    "potential_quadruples = []\n",
    "\n",
    "for i in range(length):\n",
    "    trip = triples[i]\n",
    "    id1, id2, id3 = trip[0], trip[1], trip[2]\n",
    "    \n",
    "    for j in range(length):\n",
    "        if i != j:\n",
    "            itt = triples[j]\n",
    "            id4, id5, id6 = itt[0], itt[1], itt[2]\n",
    "            \n",
    "            temp = []\n",
    "            \n",
    "            if (id1 == id4):\n",
    "                if (id2 == id5):\n",
    "                    temp = sorted ((id1, id2, id3, id6))\n",
    "                elif (id2 == id6):\n",
    "                    temp = sorted ((id1, id2, id3, id5))\n",
    "                elif (id3 == id5):\n",
    "                    temp = sorted ((id1, id2, id3, id6))\n",
    "                elif (id3 == id6):\n",
    "                    temp = sorted ((id1, id2, id3, id5))\n",
    "            elif (id2 == id4):\n",
    "                if (id1 == id5):\n",
    "                    temp = sorted ((id1, id2, id3, id6))\n",
    "                elif (id1 == id6):\n",
    "                    temp = sorted ((id1, id2, id3, id5))\n",
    "                elif (id3 == id5):\n",
    "                    temp = sorted ((id1, id2, id3, id6))\n",
    "                elif (id3 == id6):\n",
    "                    temp = sorted ((id1, id2, id3, id5))\n",
    "            elif (id3 == id4):\n",
    "                if (id1 == id5):\n",
    "                    temp = sorted ((id1, id2, id3, id6))\n",
    "                elif (id1 == id6):\n",
    "                    temp = sorted ((id1, id2, id3, id5))\n",
    "                elif (id2 == id5):\n",
    "                    temp = sorted ((id1, id2, id3, id6))\n",
    "                elif (id2 == id6):\n",
    "                    temp = sorted ((id1, id2, id3, id5))\n",
    "                        \n",
    "                \n",
    "            elif (id1 == id5):\n",
    "                if (id2 == id4):\n",
    "                    temp = sorted ((id1, id2, id3, id6))\n",
    "                elif (id2 == id6):\n",
    "                    temp = sorted ((id1, id2, id3, id4))\n",
    "                elif (id3 == id4):\n",
    "                    temp = sorted ((id1, id2, id3, id6))\n",
    "                elif (id3 == id6):\n",
    "                    temp = sorted ((id1, id2, id3, id4))\n",
    "            elif (id2 == id5):\n",
    "                if (id1 == id4):\n",
    "                    temp = sorted ((id1, id2, id3, id6))\n",
    "                elif (id1 == id6):\n",
    "                    temp = sorted ((id1, id2, id3, id4))\n",
    "                elif (id3 == id4):\n",
    "                    temp = sorted ((id1, id2, id3, id6))\n",
    "                elif (id3 == id6):\n",
    "                    temp = sorted ((id1, id2, id3, id4))\n",
    "            elif (id3 == id5):\n",
    "                if (id1 == id4):\n",
    "                    temp = sorted ((id1, id2, id3, id6))\n",
    "                elif (id1 == id6):\n",
    "                    temp = sorted ((id1, id2, id3, id4))\n",
    "                elif (id2 == id4):\n",
    "                    temp = sorted ((id1, id2, id3, id6))\n",
    "                elif (id2 == id6):\n",
    "                    temp = sorted ((id1, id2, id3, id4))\n",
    "                        \n",
    "            elif (id1 == id6):\n",
    "                if (id2 == id4):\n",
    "                    temp = sorted (id1, id2, id3, id5)\n",
    "                elif (id2 == id5):\n",
    "                    temp = sorted (id1, id2, id3, id4)\n",
    "                elif (id3 == id4):\n",
    "                    temp = sorted (id1, id2, id3, id5)\n",
    "                elif (id3 == id5):\n",
    "                    temp = sorted (id1, id2, id3, id4)\n",
    "            elif (id2 == id6):\n",
    "                if (id1 == id4):\n",
    "                    temp = sorted (id1, id2, id3, id5)\n",
    "                elif (id1 == id5):\n",
    "                    temp = sorted (id1, id2, id3, id4)\n",
    "                elif (id3 == id4):\n",
    "                    temp = sorted (id1, id2, id3, id5)\n",
    "                elif (id3 == id5):\n",
    "                    temp = sorted (id1, id2, id3, id4)\n",
    "            elif (id3 == id6):\n",
    "                if (id1 == id4):\n",
    "                    temp = sorted (id1, id2, id3, id5)\n",
    "                elif (id1 == id5):\n",
    "                    temp = sorted (id1, id2, id3, id4)\n",
    "                elif (id2 == id4):\n",
    "                    temp = sorted (id1, id2, id3, id5)\n",
    "                elif (id2 == id5):\n",
    "                    temp = sorted (id1, id2, id3, id4)\n",
    "            \n",
    "            if temp != []: potential_quadruples.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_trips(x, y):\n",
    "    id1, id2, id3 = x[0], x[1], x[2]\n",
    "    id4, id5, id6 = y[0], y[1], y[2]\n",
    "    \n",
    "    if sorted([id1, id2, id3]) == sorted([id4, id5, id6]): return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(potential_quadruples)\n",
    "quadruples = []\n",
    "\n",
    "for i in range(length):\n",
    "    pot = potential_quadruples[i]\n",
    "    id1, id2, id3, id4 = pot[0], pot[1], pot[2], pot[3]\n",
    "    \n",
    "    p1, p2, p3, p4 = (id1, id2, id3), (id1, id2, id4), (id1, id3, id4), (id2, id3, id4)\n",
    "    \n",
    "    b1, b2, b3, b4 = False, False, False, False\n",
    "    \n",
    "    for trip in triples:\n",
    "        if comp_trips(p1, trip): b1 = True\n",
    "        elif comp_trips(p2, trip): b2 = True\n",
    "        elif comp_trips(p3, trip): b3 = True\n",
    "        elif comp_trips(p4, trip): b4 = True        \n",
    "            \n",
    "    if False not in [b1, b2, b3, b4]:\n",
    "        if sorted(pot) not in quadruples:\n",
    "            quadruples.append(sorted(pot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total potential quadruples with separation 30kpc < dr < 200kpc: 406\n",
      "total quadruples with separation 30kpc < dr < 200kpc (with potential quadruples): 24\n"
     ]
    }
   ],
   "source": [
    "print('total potential quadruples with separation 30kpc < dr < 200kpc:', len(potential_quadruples))\n",
    "print('total quadruples with separation 30kpc < dr < 200kpc (with potential quadruples):', len(quadruples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quintuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(quadruples)\n",
    "potential_quintuples = []\n",
    "\n",
    "for i in range(length):\n",
    "    quad1 = sorted(quadruples[i])\n",
    "    \n",
    "    for j in range(length):\n",
    "        if i != j:\n",
    "            quad2 = sorted(quadruples[j])\n",
    "            \n",
    "            temp = []\n",
    "            \n",
    "            sect = intersection(quad1, quad2)\n",
    "            \n",
    "            if len(sect) == 3:\n",
    "                temp = [curr for curr in sect]\n",
    "                \n",
    "                for curr in quad1:\n",
    "                    if curr not in temp: temp.append(curr)\n",
    "                for curr in quad2:\n",
    "                    if curr not in temp: temp.append(curr)\n",
    "                \n",
    "                assert(len(temp) == 5)\n",
    "            \n",
    "            if temp != []: potential_quintuples.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_quads(x, y):\n",
    "    id1, id2, id3, id4 = x[0], x[1], x[2], x[3]\n",
    "    id5, id6, id7, id8 = y[0], y[1], y[2], y[3]\n",
    "    \n",
    "    if sorted([id1, id2, id3, id4]) == sorted([id5, id6, id7, id8]): return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(potential_quintuples)\n",
    "quintuples = []\n",
    "\n",
    "for i in range(length):\n",
    "    pot = potential_quintuples[i]\n",
    "    id1, id2, id3, id4, id5 = pot[0], pot[1], pot[2], pot[3], pot[4]\n",
    "    \n",
    "    p1, p2, p3, p4, p5 = (id1, id2, id3, id4), (id1, id2, id4, id5), (id1, id3, id4, id5), (id2, id3, id4, id5), (id1, id2, id3, id5)\n",
    "    \n",
    "    b1, b2, b3, b4, b5 = False, False, False, False, False\n",
    "    \n",
    "    for quad in quadruples:\n",
    "        if comp_quads(p1, quad): b1 = True\n",
    "        elif comp_quads(p2, quad): b2 = True\n",
    "        elif comp_quads(p3, quad): b3 = True\n",
    "        elif comp_quads(p4, quad): b4 = True   \n",
    "        elif comp_quads(p5, quad): b5 = True\n",
    "            \n",
    "    if False not in [b1, b2, b3, b4, b5]:\n",
    "        if sorted(pot) not in quintuples:\n",
    "            quintuples.append(sorted(pot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Quadruple Subsets from Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_triples = []\n",
    "\n",
    "for trip in triples:\n",
    "    id1, id2, id3 = trip[0], trip[1], trip[2]\n",
    "    isQuad = False\n",
    "    \n",
    "    for quad in quadruples:\n",
    "        if id1 in quad and id2 in quad and id3 in quad: isQuad = True\n",
    "    \n",
    "    if not isQuad: unique_triples.append(trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total triples without filtering out quadruple sub-tuples: 126\n",
      "total triples not within quadruples: 64\n"
     ]
    }
   ],
   "source": [
    "print('total triples without filtering out quadruple sub-tuples:', len(triples))\n",
    "print('total triples not within quadruples:', len(unique_triples))\n",
    "\n",
    "triples = unique_triples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Quintuple Subsets from Quadruples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_quadruples = []\n",
    "\n",
    "for quad in quadruples:\n",
    "    id1, id2, id3, id4 = quad[0], quad[1], quad[2], quad[3]\n",
    "    isQuint = False\n",
    "    \n",
    "    for quint in quintuples:\n",
    "        if id1 in quint and id2 in quint and id3 in quint and id4 in quint: isQuint = True\n",
    "    \n",
    "    if not isQuint: unique_quadruples.append(quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total quadruples without filtering out quintuple sub-tuples: 24\n",
      "total quadruples not within quintuples: 10\n"
     ]
    }
   ],
   "source": [
    "print('total quadruples without filtering out quintuple sub-tuples:', len(quadruples))\n",
    "print('total quadruples not within quintuples:', len(unique_quadruples))\n",
    "\n",
    "quadruples = unique_quadruples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final IDs of Tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[190330923700, 190754027667, 191661329745],\n",
       " [190330923700, 190754027667, 191117390607],\n",
       " [190300387606, 190330923700, 191661329745],\n",
       " [190330923700, 191661329745, 192266720145],\n",
       " [190330923700, 191117390607, 192266720145],\n",
       " [202057799372, 202117897875, 202299903826],\n",
       " [201603851309, 202057799372, 202299903826],\n",
       " [288759510889, 290392807456, 290967678486],\n",
       " [288366189469, 288759510889, 290392807456],\n",
       " [319384488647, 319868472095, 320472960611],\n",
       " [318930419617, 319868472095, 320472960611],\n",
       " [319868472095, 320201040644, 320472960611],\n",
       " [318779164189, 319868472095, 320472960611],\n",
       " [328855687577, 329763440569, 331911201567],\n",
       " [328855687577, 329763440569, 331517869025],\n",
       " [328855687577, 329763440569, 332697487041],\n",
       " [182041328590, 182918567646, 183251757629],\n",
       " [181618224650, 182918567646, 183251757629],\n",
       " [182041328590, 183251757629, 183584172159],\n",
       " [181618224650, 183251757629, 183584172159],\n",
       " [294241478728, 295391110693, 297992407150],\n",
       " [283143487325, 284444402325, 284958547835],\n",
       " [281146998310, 282145473814, 284444402325],\n",
       " [202303119316, 203301391352, 204390237361],\n",
       " [242381269078, 242471535139, 243197540559],\n",
       " [241927018644, 242381269078, 243197540559],\n",
       " [185091491899, 185908115390, 186180574434],\n",
       " [306069494183, 306946980770, 307884631732],\n",
       " [183275859635, 183850582177, 184092906742],\n",
       " [222888700743, 223856623779, 224310599316],\n",
       " [222102068778, 222888700743, 224310599316],\n",
       " [167887408084, 168976039561, 169339441068],\n",
       " [272410305560, 272561945994, 272924808584],\n",
       " [307552864542, 308127988564, 309579653084],\n",
       " [329119572465, 329240748547, 330571484498],\n",
       " [328575314526, 329119572465, 330571484498],\n",
       " [329119572465, 329240748547, 330420162960],\n",
       " [328575314526, 329119572465, 330420162960],\n",
       " [197847365902, 198452140393, 199783420961],\n",
       " [187469176526, 188406959469, 188437055531],\n",
       " [277505860797, 278443550380, 278836932354],\n",
       " [301383933326, 301595831858, 302231004816],\n",
       " [301383933326, 301565383778, 301595831858],\n",
       " [167246432518, 331715363543, 332623160591],\n",
       " [167246432518, 167851295093, 331715363543],\n",
       " [258052176737, 258173028212, 260108725725],\n",
       " [258052176737, 258173028212, 259231783697],\n",
       " [258052176737, 258173028212, 259504044745],\n",
       " [190968812892, 192330233368, 192390507858],\n",
       " [227352357418, 228138758424, 228774283450],\n",
       " [227352357418, 228652947968, 228774283450],\n",
       " [242565968457, 243473143907, 244259814425],\n",
       " [280219815858, 281187799404, 282125345878],\n",
       " [320201326348, 321290392332, 321532287856],\n",
       " [176147049430, 176902952889, 177719812932],\n",
       " [255041224273, 256553905806, 256765386318],\n",
       " [328833556693, 329438694205, 330618202228],\n",
       " [281836404849, 282077997839, 282743453851],\n",
       " [208293526430, 208838218927, 208898729954],\n",
       " [289889274870, 290524365361, 291129238918],\n",
       " [275755580993, 276057915986, 276844553446],\n",
       " [182888729967, 184280334481, 184764301500],\n",
       " [324587499614, 325404062589, 325615955544],\n",
       " [205996344521, 206056987504, 206692248492]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[188575103637, 188605810153, 188847689217, 190783793705],\n",
       " [188575103637, 188605810153, 189664114719, 190783793705],\n",
       " [188575103637, 188605810153, 188635972273, 190783793705],\n",
       " [269000537783, 269725954826, 269847680861, 270905979821],\n",
       " [301356899793, 302173721354, 302748113800, 303655767889],\n",
       " [214843751341, 215418721290, 216054251780, 216145089724],\n",
       " [281146998310, 281207404777, 281540435352, 282145473814],\n",
       " [326353608267, 327321437652, 327442657705, 327714621701],\n",
       " [281593215811, 281835463287, 283377954772, 283710699326],\n",
       " [281774523287, 281835463287, 283377954772, 283710699326]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadruples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating BH Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z=3 snap: 214\n",
    "# z=2 snap: 348\n",
    "\n",
    "snap = 214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------PIG file info------------\n",
      "Redshift = 3.00\n",
      "Lbox = 250000 ckpc/h\n",
      "NfofGroups = 193500739\n",
      "------cosmological parameters-----\n",
      "h = 0.6774\n",
      "Omega_m = 0.3089\n",
      "Omega_b = 0.0486\n",
      "Omega_l = 0.6911\n"
     ]
    }
   ],
   "source": [
    "if snap > 294:\n",
    "    pig = BigFile('/hildafs/datasets/Asterix/PIG2/PIG_%03d'%snap)\n",
    "else:\n",
    "    pig = BigFile('/hildafs/datasets/Asterix/PIG_files/PIG_%03d'%snap)\n",
    "\n",
    "# you can check the redshift by reading the attributes of the snapshot\n",
    "battr = pig[\"Header\"].attrs\n",
    "scale_fac = battr[\"Time\"][0]\n",
    "redshift = 1./battr[\"Time\"][0] - 1\n",
    "Lbox = battr['BoxSize']\n",
    "hh = battr['HubbleParam']\n",
    "om0 = battr['Omega0']\n",
    "omb = battr['OmegaBaryon']\n",
    "oml = battr['OmegaLambda']\n",
    "Nfof = battr['NumFOFGroupsTotal']\n",
    "sigma8 = 0.82\n",
    "print('----------PIG file info------------')\n",
    "\n",
    "print('Redshift = %.2f'%redshift)\n",
    "print('Lbox = %d ckpc/h'%Lbox)\n",
    "print('NfofGroups = %d'%Nfof)\n",
    "\n",
    "print('------cosmological parameters-----')\n",
    "print('h = %.4f'%hh)\n",
    "print('Omega_m = %.4f'%om0)\n",
    "print('Omega_b = %.4f'%omb)\n",
    "print('Omega_l = %.4f'%oml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This helps you locate particles of each type if you know the group index\n",
    "Length = pig.open('FOFGroups/LengthByType')[:]\n",
    "OffsetByType = np.cumsum(Length,axis=0)\n",
    "a1 = np.array([[0,0,0,0,0,0]],dtype=np.uint64)\n",
    "OffsetByType = np.append(a1,OffsetByType,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID of the BH of interest: 258052176737\n"
     ]
    }
   ],
   "source": [
    "# \"5\" means BH particles, \"ID\" means we are loading the ID of each BH particle\n",
    "# here we only load the first 1000000, because most of the massive BHs are there\n",
    "BHIDs = pig.open('5/ID')[:]\n",
    "\n",
    "# pick a fairly massive black hole as an example\n",
    "id1 = 258052176737\n",
    "idx1 = (BHIDs==id1).nonzero()[0][0]\n",
    "print('ID of the BH of interest:',id1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxdir = '/hildafs/datasets/Asterix/subfind/subfind-idx/subfind_%03d/'%snap\n",
    "bf = BigFile(idxdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bh_group(pig,bid):\n",
    "    bhidx = (BHIDs==bid).nonzero()[0][0]\n",
    "    groupidx = pig.open('5/GroupID')[bhidx]-1\n",
    "    subidx = sfile.open('5/Subfind-SubGrpIndex')[bhidx]\n",
    "    return bhidx,groupidx,subidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subfind_chunk(snap):\n",
    "    subdir = '/hildafs/datasets/Asterix/subfind/subfind_%d/*'%snap\n",
    "    chunk_list = []\n",
    "    maxgroup_list = []\n",
    "    for ff in sorted(glob.glob(subdir)):\n",
    "        cname = ff.split('/')[-1]\n",
    "        chunk = int(cname.split('.')[0][5:])\n",
    "        maxgroup = int(cname.split('.')[1])\n",
    "        chunk_list.append(chunk)\n",
    "        maxgroup_list.append(maxgroup)\n",
    "    sort = np.argsort(chunk_list)\n",
    "    \n",
    "    chunk_list = np.array(chunk_list)[sort]\n",
    "    maxgroup_list = np.array(maxgroup_list)[sort]\n",
    "    return chunk_list, maxgroup_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_list, maxgroup_list = get_subfind_chunk(snap)\n",
    "def group_chunk_dir(groupidx,snap):\n",
    "    sub_root = '/hildafs/datasets/Asterix/subfind/subfind_%03d/'%snap\n",
    "    chunk = np.nonzero(maxgroup_list-1>=groupidx)[0][0]\n",
    "    # print('groupidx',groupidx,'chunk',chunk,maxgroup_list[chunk-1],maxgroup_list[chunk])\n",
    "    \n",
    "    subdir = sub_root + 'chunk%d.%d/output/'%(chunk,maxgroup_list[chunk])\n",
    "    tabfile = subdir + 'fof_subhalo_tab_%03d.hdf5'%snap\n",
    "    return subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['Config', 'Group', 'Header', 'IDs', 'Parameters', 'Subhalo']>\n",
      "\n",
      " ---- Available Group Properties --------\n",
      "['GroupAscale', 'GroupFirstSub', 'GroupLen', 'GroupLenType', 'GroupMass', 'GroupMassType', 'GroupNsubs', 'GroupOffsetType', 'GroupPos', 'GroupVel', 'Group_M_Crit200', 'Group_M_Crit500', 'Group_M_Mean200', 'Group_M_TopHat200', 'Group_R_Crit200', 'Group_R_Crit500', 'Group_R_Mean200', 'Group_R_TopHat200']\n",
      "\n",
      " ---- Available Subhalo Properties --------\n",
      "['SubhaloCM', 'SubhaloGroupNr', 'SubhaloHalfmassRad', 'SubhaloHalfmassRadType', 'SubhaloIDMostbound', 'SubhaloLen', 'SubhaloLenType', 'SubhaloMass', 'SubhaloMassType', 'SubhaloOffsetType', 'SubhaloParentRank', 'SubhaloPos', 'SubhaloRankInGr', 'SubhaloSpin', 'SubhaloVel', 'SubhaloVelDisp', 'SubhaloVmax', 'SubhaloVmaxRad']\n"
     ]
    }
   ],
   "source": [
    "sfile = BigFile('/hildafs/datasets/Asterix/subfind/subfind-idx/subfind_%03d'%snap)\n",
    "subdir = group_chunk_dir(groupidx=10,snap=snap)\n",
    "tabfile = subdir + 'fof_subhalo_tab_%03d.hdf5'%snap\n",
    "with h5py.File(tabfile,'r') as sbgrp:\n",
    "    print(sbgrp.keys())\n",
    "    print('\\n ---- Available Group Properties --------')\n",
    "    print(list(sbgrp['Group'].keys()))\n",
    "    print('\\n ---- Available Subhalo Properties --------')\n",
    "    print(list(sbgrp['Subhalo'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subfind_obt(groupidx,snap):\n",
    "    subdir = group_chunk_dir(groupidx,snap)\n",
    "    tabfile = subdir + 'fof_subhalo_tab_%03d.hdf5'%snap\n",
    "    \n",
    "    with h5py.File(tabfile,'r') as sbgrp:\n",
    "        zeros = np.array([[0,0,0,0,0,0]],dtype=np.uint64)\n",
    "\n",
    "        glbt = sbgrp['Group']['GroupLenType'][:]\n",
    "        gobt = np.concatenate([zeros,np.cumsum(glbt,axis=0)],axis=0).astype(int)\n",
    "\n",
    "\n",
    "        first_sub = sbgrp['Group']['GroupFirstSub'][:]\n",
    "        nsub = sbgrp['Group']['GroupNsubs'][:]\n",
    "\n",
    "        # print('total subhalos in this chunk:',sum(nsub))\n",
    "\n",
    "\n",
    "        slbt = sbgrp['Subhalo']['SubhaloLenType'][:]\n",
    "        sobt = np.zeros_like(slbt)\n",
    "        sobt = np.concatenate([zeros,sobt],axis=0).astype(int)\n",
    "        for i,f in enumerate(first_sub):\n",
    "            if f < 0:  # skip groups with no subhalo\n",
    "                continue\n",
    "            # align the first subgroup with group starting point\n",
    "            sobt[f] = gobt[i]\n",
    "            # assign the rest of the subgroup starting idx\n",
    "            sobt[f+1:f+nsub[i]] = sobt[f] + np.cumsum(slbt[f:f+nsub[i]-1],axis=0)\n",
    "            \n",
    "        return gobt,sobt,first_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_bh(groupidx,bhid,snap,gobt,sobt,first_sub):\n",
    "    subdir = group_chunk_dir(groupidx,snap)\n",
    "    if snap < 294:\n",
    "        grpfile = subdir + 'snap_%03d.hdf5'%snap\n",
    "    else:\n",
    "        grpfile = subdir + 'snap-groupordered_%03d.hdf5'%snap\n",
    "    \n",
    "    with h5py.File(grpfile,'r') as sbgrp:\n",
    "        id5 = sbgrp['PartType5']['ParticleIDs'][:]\n",
    "        bidx = (id5==bhid).nonzero()[0][0]\n",
    "        \n",
    "    gidx = (gobt[:,5]>bidx).nonzero()[0][0]-1\n",
    "    \n",
    "    sidx = -1\n",
    "    \n",
    "    if len((sobt[:,5]>bidx).nonzero()) > 0:\n",
    "        if len((sobt[:,5]>bidx).nonzero()[0]) > 0:\n",
    "            sidx = (sobt[:,5]>bidx).nonzero()[0][0]-1\n",
    "\n",
    "    if sidx == -1:\n",
    "        print(\"Missing BHID:\",bhid)\n",
    "        return bidx,gidx,sidx,0,0\n",
    "        \n",
    "    # make sure that we get the correct BH group\n",
    "    bh_group = id5[gobt[gidx][5]:gobt[gidx+1][5]]\n",
    "    bh_sbgrp = id5[sobt[sidx][5]:sobt[sidx+1][5]]\n",
    "    assert(bhid in bh_group)\n",
    "    assert(bhid in bh_sbgrp)\n",
    "    \n",
    "    sbegin = first_sub[gidx]\n",
    "    send = first_sub[gidx+1]\n",
    "\n",
    "    return bidx,gidx,sidx,sbegin,send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_summary(groupidx,snap,gidx,feature_list):\n",
    "    subdir = group_chunk_dir(groupidx,snap)\n",
    "    tabfile = subdir + 'fof_subhalo_tab_%03d.hdf5'%snap\n",
    "    \n",
    "    output = {}\n",
    "    with h5py.File(tabfile,'r') as sbgrp:\n",
    "        for ff in feature_list:\n",
    "            try: \n",
    "                output[ff] = sbgrp['Group'][ff][gidx]\n",
    "            except KeyError:\n",
    "                print('skipping %s: feature does not exist!'%ff) \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subhalo_summary(groupidx,snap,gidx,sidx,sbegin,send,feature_list,main_sub=False):\n",
    "    subdir = group_chunk_dir(groupidx,snap)\n",
    "    tabfile = subdir + 'fof_subhalo_tab_%03d.hdf5'%snap\n",
    "    \n",
    "    if main_sub:\n",
    "        print('output the main subhalo in group')\n",
    "        sidx = sbegin\n",
    "\n",
    "    \n",
    "    output = {}\n",
    "    with h5py.File(tabfile,'r') as sbgrp:\n",
    "        for ff in feature_list:\n",
    "            try: \n",
    "                output[ff] = sbgrp['Subhalo'][ff][sidx]\n",
    "            except KeyError:\n",
    "                print('skipping %s: feature does not exist!'%ff)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These arrays are necessary for locating a BH in the detials file\n",
    "path = '/hildafs/datasets/Asterix/BH_details_dict/Read-Blackhole-Detail'\n",
    "detail = BigFile(path)\n",
    "AllIDs = detail.open('BHID')[:]\n",
    "Index = detail.open('Index')[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bh_history(bhid):\n",
    "    idx = (AllIDs==bhid).nonzero()[0][0]\n",
    "    chunk = Index[idx]\n",
    "    # print('File number of the target BHs:',chunk)\n",
    "    # now load bh data\n",
    "    outdir = '/hildafs/datasets/Asterix/BH_details_dict/'\n",
    "    save = outdir+'BlackholeDetails-%04d'%chunk\n",
    "    with open(save, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        f.close()\n",
    "    bh = data[bhid]\n",
    "    return bh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triples Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = tuples_z2_z3.triples_z2_dr200\n",
    "quadruples = tuples_z2_z3.quadruples_z2_dr200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-29e8d68931b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# id1 = 258052176737\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mbidx_bf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgidx_bf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msidx_bf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bh_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mid1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOffsetByType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgidx_bf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOffsetByType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgidx_bf\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-228163fb230d>\u001b[0m in \u001b[0;36mget_bh_group\u001b[0;34m(pig, bid)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_bh_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mbhidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBHIDs\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mbid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mgroupidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'5/GroupID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbhidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msubidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'5/Subfind-SubGrpIndex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbhidx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbhidx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgroupidx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubidx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "trips_vals = []\n",
    "\n",
    "count = 1\n",
    "\n",
    "for trip in triples:\n",
    "    \n",
    "    if count % (len(triples)//10) == 0:\n",
    "        print(\"Count =\", count)\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    for id1 in trip:\n",
    "        \n",
    "        # id1 = 258052176737\n",
    "        bidx_bf,gidx_bf,sidx_bf = get_bh_group(pig,id1)\n",
    "\n",
    "        start,end = OffsetByType[gidx_bf],OffsetByType[gidx_bf+1]\n",
    "\n",
    "        gobt,sobt,first_sub = subfind_obt(groupidx=gidx_bf,snap=snap)\n",
    "\n",
    "        bidx,gidx,sidx,sbegin,send = place_bh(gidx_bf,bhid=id1,snap=snap,gobt=gobt,sobt=sobt,first_sub=first_sub)\n",
    "\n",
    "        # look out for reassigned subhalo on some large BHs\n",
    "        sub_info = subhalo_summary(groupidx=gidx_bf,snap=snap,gidx=gidx,sidx=sidx,\\\n",
    "                                   sbegin=sbegin,send=send,feature_list=['SubhaloPos','SubhaloMassType'],main_sub=False)\n",
    "\n",
    "        gal_center = sub_info['SubhaloPos']\n",
    "        gal_mass = sub_info['SubhaloMassType'][4]*1e10/hh\n",
    "        bhmass = pig.open('5/BlackholeMass')[bidx_bf]*1e10/hh[0]\n",
    "\n",
    "        if gal_mass < bhmass:\n",
    "            # reassign galaxy\n",
    "            mass4 = pig.open('4/Mass')[start[4]:end[4]]\n",
    "            star_sid = bf.open('4/Subfind-SubGrpIndex2')[start[4]:end[4]]\n",
    "            bh_sbgrp = bf.open('5/Subfind-SubGrpIndex2')[bidx_bf]\n",
    "            mask4_tgt = star_sid==bh_sbgrp\n",
    "\n",
    "            gal_mass = np.sum(mass4[mask4_tgt])*1e10/hh\n",
    "\n",
    "        bhpos = pig.open('5/Position')[bidx_bf]\n",
    "        \n",
    "        x1,y1,z1 = bhpos[0],bhpos[1],bhpos[2]\n",
    "        x2,y2,z2 = gal_center[0],gal_center[1],gal_center[2]\n",
    "        \n",
    "        offset = (math.sqrt ((x2 - x1)**2 + (y2 - y1)**2 + (z2 - z1)**2) / (1 + redshift) / hh)[0]\n",
    "        \n",
    "        bh1 = get_bh_history(id1)\n",
    "        \n",
    "        mask1 = bh1['z'] == redshift\n",
    "        \n",
    "        bh1 = bh1[mask1]\n",
    "        \n",
    "        lum1 = calc_lx(bh1['Mdot']*mdot_msun_yr)[0]\n",
    "        \n",
    "        curr = (id1, bhmass, gal_mass[0], offset, lum1)\n",
    "        trips_vals.append(curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_info_z2_dr200 = np.array(trips_vals,\n",
    "    dtype = [('BHID', '<i8'), ('BHMass', '<f8'), ('HostMass', '<f8'), ('Offset', '<f8'), ('LumX', '<f8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trips_info_z2_dr200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trips_info_z2_dr200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadruples Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quads_vals = []\n",
    "missing_quads = []\n",
    "count = 1\n",
    "\n",
    "for quad in quadruples:\n",
    "    \n",
    "    if count % (len(quadruples)//10) == 0:\n",
    "        print(\"Count =\", count)\n",
    "        \n",
    "    count += 1\n",
    "        \n",
    "    for id1 in quad:\n",
    "        # id1 = 258052176737\n",
    "        \n",
    "        bidx_bf,gidx_bf,sidx_bf = get_bh_group(pig,id1)\n",
    "\n",
    "        start,end = OffsetByType[gidx_bf],OffsetByType[gidx_bf+1]\n",
    "\n",
    "        gobt,sobt,first_sub = subfind_obt(groupidx=gidx_bf,snap=snap)\n",
    "\n",
    "        bidx,gidx,sidx,sbegin,send = place_bh(gidx_bf,bhid=id1,snap=snap,gobt=gobt,sobt=sobt,first_sub=first_sub)\n",
    "        \n",
    "        if sidx == -1:\n",
    "            missing_quads.append(id1)\n",
    "        else:\n",
    "            # look out for reassigned subhalo on some large BHs\n",
    "            sub_info = subhalo_summary(groupidx=gidx_bf,snap=snap,gidx=gidx,sidx=sidx,\\\n",
    "                                       sbegin=sbegin,send=send,feature_list=['SubhaloPos','SubhaloMassType'],main_sub=False)\n",
    "\n",
    "            gal_center = sub_info['SubhaloPos']\n",
    "            gal_mass = sub_info['SubhaloMassType'][4]*1e10/hh\n",
    "            bhmass = pig.open('5/BlackholeMass')[bidx_bf]*1e10/hh[0]\n",
    "\n",
    "            if gal_mass < bhmass:\n",
    "                # reassign galaxy\n",
    "                mass4 = pig.open('4/Mass')[start[4]:end[4]]\n",
    "                star_sid = bf.open('4/Subfind-SubGrpIndex2')[start[4]:end[4]]\n",
    "                bh_sbgrp = bf.open('5/Subfind-SubGrpIndex2')[bidx_bf]\n",
    "                mask4_tgt = star_sid==bh_sbgrp\n",
    "\n",
    "                gal_mass = np.sum(mass4[mask4_tgt])*1e10/hh\n",
    "\n",
    "            bhpos = pig.open('5/Position')[bidx_bf]\n",
    "\n",
    "            x1,y1,z1 = bhpos[0],bhpos[1],bhpos[2]\n",
    "            x2,y2,z2 = gal_center[0],gal_center[1],gal_center[2]\n",
    "\n",
    "            offset = (math.sqrt ((x2 - x1)**2 + (y2 - y1)**2 + (z2 - z1)**2) / (1 + redshift) / hh)[0]\n",
    "\n",
    "            bh1 = get_bh_history(id1)\n",
    "\n",
    "            mask1 = bh1['z'] == redshift\n",
    "\n",
    "            bh1 = bh1[mask1]\n",
    "\n",
    "            lum1 = calc_lx(bh1['Mdot']*mdot_msun_yr)[0]\n",
    "\n",
    "            curr = (id1, bhmass, gal_mass[0], offset, lum1)\n",
    "            quads_vals.append(curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quads_info_z2_dr200 = np.array(quads_vals,\n",
    "    dtype = [('BHID', '<i8'), ('BHMass', '<f8'), ('HostMass', '<f8'), ('Offset', '<f8'), ('LumX', '<f8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(quads_info_z2_dr200)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "quads_info_z2_dr200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_quads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
